{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This file\n",
    "- tokenizes the descriptions from spreadsheet2\n",
    "- vactorizes the word frequency for each course\n",
    "- outputs three files, courses, words and the word-freq matrix\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spreadsheet2.csv')\n",
    "df.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>dept</th>\n",
       "      <th>cno</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>prerequisite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>CSC</td>\n",
       "      <td>457</td>\n",
       "      <td>Expert Systems</td>\n",
       "      <td>A study of the development of expert systems. ...</td>\n",
       "      <td>CSC403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>CSC</td>\n",
       "      <td>458</td>\n",
       "      <td>Symbolic Programming</td>\n",
       "      <td>Concepts of symbolic programming as embodied i...</td>\n",
       "      <td>CSC403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>DSC</td>\n",
       "      <td>478</td>\n",
       "      <td>Programming Machine Learning Applications</td>\n",
       "      <td>The course will focus on the implementations o...</td>\n",
       "      <td>DSC441-CSC401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>CSC</td>\n",
       "      <td>480</td>\n",
       "      <td>Artificial Intelligence I</td>\n",
       "      <td>An in-depth survey of important concepts probl...</td>\n",
       "      <td>CSC403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>CSC</td>\n",
       "      <td>481</td>\n",
       "      <td>Introduction to Image Processing</td>\n",
       "      <td>The course is a prerequisite for more advanced...</td>\n",
       "      <td>CSC412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     level dept  cno  \\\n",
       "0  Artificial Intelligence  CSC  457   \n",
       "1  Artificial Intelligence  CSC  458   \n",
       "2  Artificial Intelligence  DSC  478   \n",
       "3  Artificial Intelligence  CSC  480   \n",
       "4  Artificial Intelligence  CSC  481   \n",
       "\n",
       "                                        name  \\\n",
       "0                             Expert Systems   \n",
       "1                       Symbolic Programming   \n",
       "2  Programming Machine Learning Applications   \n",
       "3                  Artificial Intelligence I   \n",
       "4           Introduction to Image Processing   \n",
       "\n",
       "                                         description   prerequisite  \n",
       "0  A study of the development of expert systems. ...         CSC403  \n",
       "1  Concepts of symbolic programming as embodied i...         CSC403  \n",
       "2  The course will focus on the implementations o...  DSC441-CSC401  \n",
       "3  An in-depth survey of important concepts probl...         CSC403  \n",
       "4  The course is a prerequisite for more advanced...         CSC412  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load every discription into a list\n",
    "doc_complete = [df.iloc[i,4] for i in range(df.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation) \n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning\n",
    "def clean(doc):\n",
    "    stop_free = \" \".join([w for w in doc.lower().split() if w not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_clean = [clean(doc) for doc in doc_complete]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert Systems\n",
      "study development expert system student use commercial package develop standalone embedded expert system topic include rulebased system decision tree forward backward chaining inference reasoning uncertainty intelligent agent\n",
      "\n",
      "Symbolic Programming\n",
      "concept symbolic programming embodied language lisp basic data control structure lisp symbolic expression interpreter function recursion iteration technique prototyping building conceptually advanced system environment encourages procedural data abstraction advanced topic may include prolog intelligent tutoring system intelligent agent natural language processing assignment focus basic ai technique class intended anyone need rapidly develop large complex system\n",
      "\n",
      "Programming Machine Learning Applications\n",
      "course focus implementation various data mining machine learning technique using highlevel programming language student hand experience developing supervised unsupervised machine learning algorithm learn employ technique context popular application including automatic personalization recommender system searching ranking text mining group community discovery social medium analytics\n",
      "\n",
      "Artificial Intelligence I\n",
      "indepth survey important concept problem technique artificial intelligence including search knowledge representation logical reasoning reasoning uncertainty particular focus unifying theme course concept intelligent agent prior knowledge ai required course particularly suitable graduate advanced undergraduate student want gain technical background necessary build intelligent system want prepare advanced work ai concept technique learned course directly applicable many area computer science including software design distributed system database information management retrieval\n",
      "\n",
      "Introduction to Image Processing\n",
      "course prerequisite advanced visual computing vc course student challenged implement vc algorithm real world application topic covered course include component image processing system application element visual perception sampling quantization image enhancement histogram equalization color space transformation introduction segmentation edge detection morphological image processing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## see the first five results\n",
    "for i in range(5):\n",
    "    print(df.iloc[i,3])\n",
    "    print(doc_clean[i], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<164x1428 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 5361 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## feed the documents into vactor object\n",
    "X = vectorizer.fit_transform(doc_clean)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get all the tokens\n",
    "words = vectorizer.get_feature_names()\n",
    "# print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(164, 1428)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get the 2d word frequency array\n",
    "matirx = X.toarray()\n",
    "print(matirx.shape)\n",
    "matirx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(164, 1428)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## write the matrix into csv\n",
    "mat = pd.DataFrame(matirx)\n",
    "mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## word freq matrix\n",
    "mat.to_csv(\"word_freq.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## courses\n",
    "courses = [str(df.iloc[i,1])+str(df.iloc[i,2]) for i in range(df.shape[0])]\n",
    "pd.DataFrame({'courses':courses}).to_csv(\"courses.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## words\n",
    "pd.DataFrame({'words':words}).to_csv(\"words.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
